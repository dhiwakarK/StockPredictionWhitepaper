{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including pandas, numpy, and sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical operations\n",
    "from sklearn.model_selection import TimeSeriesSplit  # For time series cross-validation\n",
    "from sklearn.linear_model import LinearRegression  # For the linear regression model\n",
    "from sklearn.metrics import mean_squared_error  # For calculating the mean squared error\n",
    "from sklearn.preprocessing import StandardScaler  # For standardizing the features\n",
    "from matplotlib import pyplot as plt  # For data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Explore the Dataset\n",
    "Load the ACN_data.csv file into a pandas DataFrame and perform initial exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   open    high    low  close   volume Name\n",
      "0  2013-02-08  73.01  73.710  72.82  73.31  2000477  ACN\n",
      "1  2013-02-11  73.09  73.270  72.10  73.07  1880055  ACN\n",
      "2  2013-02-12  72.89  73.495  72.58  73.37  1710274  ACN\n",
      "3  2013-02-13  73.32  73.710  73.20  73.56  1884631  ACN\n",
      "4  2013-02-14  73.21  73.500  72.66  73.13  2096346  ACN\n",
      "            date     open    high     low   close   volume Name\n",
      "1254  2018-02-01  160.155  161.13  159.54  160.46  1692576  ACN\n",
      "1255  2018-02-02  159.980  160.27  156.63  156.90  2183611  ACN\n",
      "1256  2018-02-05  156.120  159.27  150.73  151.83  3733711  ACN\n",
      "1257  2018-02-06  150.290  155.18  149.43  154.69  4259634  ACN\n",
      "1258  2018-02-07  154.220  158.93  153.07  155.15  2918659  ACN\n",
      "The shape of the DataFrame is: (1259, 7)\n",
      "The column names are: Index(['date', 'open', 'high', 'low', 'close', 'volume', 'Name'], dtype='object')\n",
      "The data types of each column are: date       object\n",
      "open      float64\n",
      "high      float64\n",
      "low       float64\n",
      "close     float64\n",
      "volume      int64\n",
      "Name       object\n",
      "dtype: object\n",
      "The number of missing values in each column are: date      0\n",
      "open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "Name      0\n",
      "dtype: int64\n",
      "              open         high          low        close        volume\n",
      "count  1259.000000  1259.000000  1259.000000  1259.000000  1.259000e+03\n",
      "mean    101.022826   101.766440   100.348163   101.119079  2.596238e+06\n",
      "std      22.105091    22.206993    21.999712    22.129031  1.353507e+06\n",
      "min      70.580000    70.750000    69.000000    70.280000  6.018180e+05\n",
      "25%      80.680000    81.330000    80.165000    80.670000  1.879082e+06\n",
      "50%      97.800000    98.790000    96.920000    97.770000  2.328702e+06\n",
      "75%     117.020000   117.990000   116.250000   117.045000  2.972384e+06\n",
      "max     162.330000   162.600000   160.970000   162.550000  2.828439e+07\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('individual_stocks_5yr/individual_stocks_5yr/ACN_data.csv')\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Display the last 5 rows of the DataFrame\n",
    "print(df.tail())\n",
    "\n",
    "# Display the shape of the DataFrame\n",
    "print('The shape of the DataFrame is:', df.shape)\n",
    "\n",
    "# Display the column names\n",
    "print('The column names are:', df.columns)\n",
    "\n",
    "# Display the data types of each column\n",
    "print('The data types of each column are:', df.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print('The number of missing values in each column are:', df.isnull().sum())\n",
    "\n",
    "# Display summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the Data\n",
    "Clean and preprocess the data as necessary for the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values in each column are: date      0\n",
      "open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "Name      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print('The number of missing values in each column are:', missing_values)\n",
    "\n",
    "# If there are missing values, fill them with the mean of the respective column\n",
    "if missing_values.sum() > 0:\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# remove the sttock name column\n",
    "df = df.drop('Name', axis=1)\n",
    "\n",
    "#drop the date column\n",
    "df = df.drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk the Data into 5-Day Periods\n",
    "Divide the data into chunks of 5 days each for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    open    high    low  close   volume  target\n",
      "0  73.01  73.710  72.82  73.31  2000477    75.4\n",
      "1  73.09  73.270  72.10  73.07  1880055    75.4\n",
      "2  72.89  73.495  72.58  73.37  1710274    75.4\n",
      "3  73.32  73.710  73.20  73.56  1884631    75.4\n",
      "4  73.21  73.500  72.66  73.13  2096346    75.4\n",
      "         open     high     low   close   volume  target\n",
      "1250  161.250  162.580  160.33  162.55  1950655  150.29\n",
      "1251  162.330  162.600  160.97  161.19  1314847  150.29\n",
      "1252  160.960  161.160  159.11  159.70  1699965  150.29\n",
      "1253  160.090  160.945  159.73  160.70  1878301  150.29\n",
      "1254  160.155  161.130  159.54  160.46  1692576  150.29\n",
      "The shape of the new DataFrame is: (1255, 6)\n",
      "The column names of the new DataFrame are: ['open', 'high', 'low', 'close', 'volume', 'target']\n",
      "The data types of each column of the new DataFrame are: open      float64\n",
      "high      float64\n",
      "low       float64\n",
      "close     float64\n",
      "volume      int64\n",
      "target    float64\n",
      "dtype: object\n",
      "The number of missing values in each column of the new DataFrame are: open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "target    0\n",
      "dtype: int64\n",
      "              open         high          low        close        volume  \\\n",
      "count  1255.000000  1255.000000  1255.000000  1255.000000  1.255000e+03   \n",
      "mean    100.850301   101.585895   100.182054   100.948486  2.594078e+06   \n",
      "std      21.926671    22.010083    21.836110    21.956282  1.354387e+06   \n",
      "min      70.580000    70.750000    69.000000    70.280000  6.018180e+05   \n",
      "25%      80.650000    81.320000    80.150000    80.645000  1.878378e+06   \n",
      "50%      97.740000    98.620000    96.790000    97.750000  2.328081e+06   \n",
      "75%     116.990000   117.960000   116.150000   116.960000  2.969726e+06   \n",
      "max     162.330000   162.600000   160.970000   162.550000  2.828439e+07   \n",
      "\n",
      "            target  \n",
      "count  1255.000000  \n",
      "mean    101.184224  \n",
      "std      22.110905  \n",
      "min      71.630000  \n",
      "25%      80.600000  \n",
      "50%      98.010000  \n",
      "75%     117.340000  \n",
      "max     161.290000  \n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame to store the data in 5-day chunks\n",
    "df_chunks = pd.DataFrame()\n",
    "\n",
    "# Loop over the DataFrame in 5-day chunks, and assign the target to the 8th day\n",
    "for i in range(0, df.shape[0]-7, 5):\n",
    "    chunk = df.iloc[i:i+5]\n",
    "    chunk = chunk.assign(target=df.iloc[i+7]['open'])\n",
    "\n",
    "    # Use pd.concat to combine the chunks\n",
    "    df_chunks = pd.concat([df_chunks, chunk])\n",
    "\n",
    "# Reset the index of the new DataFrame\n",
    "df_chunks.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the first 5 rows of the new DataFrame\n",
    "print(df_chunks.head())\n",
    "\n",
    "# Display the last 5 rows of the new DataFrame\n",
    "print(df_chunks.tail())\n",
    "\n",
    "# Display the shape of the new DataFrame\n",
    "print('The shape of the new DataFrame is:', df_chunks.shape)\n",
    "\n",
    "# Display the column names of the new DataFrame\n",
    "print('The column names of the new DataFrame are:', df_chunks.columns.tolist())\n",
    "\n",
    "# Display the data types of each column of the new DataFrame\n",
    "print('The data types of each column of the new DataFrame are:', df_chunks.dtypes)\n",
    "\n",
    "# Check for missing values in the new DataFrame\n",
    "print('The number of missing values in each column of the new DataFrame are:', df_chunks.isnull().sum())\n",
    "\n",
    "# Display summary statistics of the new DataFrame\n",
    "print(df_chunks.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export df_chunks to a csv file\n",
    "df_chunks.to_csv('ACN_data_chunks_5days.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Linear Regression Model\n",
    "Train the linear regression model using the 40-day chunks of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the mean squared errors is: 8.514806760693755\n",
      "The mean of the root mean squared errors is: 2.8782653338678896\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Standardize the features excluding 'date'\n",
    "# We are skipping the standardization of the features, as the features are already standardized (they are withing the same range, e.g. high, medium, low etc.)\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df_chunks.drop('target', axis=1)\n",
    "y = df_chunks['target']\n",
    "\n",
    "# Initialize the TimeSeriesSplit object, the time series split ensure that the training set is always before the test set\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize a list to store the mean squared errors\n",
    "mse = []\n",
    "\n",
    "# root mean square error\n",
    "rmse = []\n",
    "\n",
    "# Loop over the time series cross-validation splits\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the mean squared error\n",
    "    mse.append(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # Calculate the root mean squared error\n",
    "    rmse.append(np.sqrt(mean_squared_error(y_test, y_pred)))  \n",
    "\n",
    "# Print the mean of the mean squared errors\n",
    "print('The mean of the mean squared errors is:', np.mean(mse))\n",
    "\n",
    "# Print the mean of the root mean squared errors\n",
    "print('The mean of the root mean squared errors is:', np.mean(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the 7th Day\n",
    "Use the trained model to predict the 7th day based on the previous 5 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted value for the 7 day is: 160.0912648737646\n"
     ]
    }
   ],
   "source": [
    "# Predict the 7 day using the trained model\n",
    "# We will use the last 5 days in our dataset as input for our prediction\n",
    "\n",
    "# Select the last 10 days\n",
    "X_new = df_chunks.iloc[-5:].drop('target', axis=1)\n",
    "#X_new = df_scaled.iloc[-10:].drop('target', axis=1)\n",
    "\n",
    "# Use the model to make a prediction\n",
    "y_new_pred = model.predict(X_new)\n",
    "\n",
    "# Print the predicted value for the 7 day\n",
    "print('The predicted value for the 7 day is:', y_new_pred[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
