{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including pandas, numpy, and sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical operations\n",
    "from sklearn.model_selection import TimeSeriesSplit  # For time series cross-validation\n",
    "from sklearn.linear_model import LinearRegression  # For the linear regression model\n",
    "from sklearn.metrics import mean_squared_error  # For calculating the mean squared error\n",
    "from sklearn.preprocessing import StandardScaler  # For standardizing the features\n",
    "from matplotlib import pyplot as plt  # For data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Explore the Dataset\n",
    "Load the ACN_data.csv file into a pandas DataFrame and perform initial exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   open    high    low  close   volume Name\n",
      "0  2013-02-08  73.01  73.710  72.82  73.31  2000477  ACN\n",
      "1  2013-02-11  73.09  73.270  72.10  73.07  1880055  ACN\n",
      "2  2013-02-12  72.89  73.495  72.58  73.37  1710274  ACN\n",
      "3  2013-02-13  73.32  73.710  73.20  73.56  1884631  ACN\n",
      "4  2013-02-14  73.21  73.500  72.66  73.13  2096346  ACN\n",
      "            date     open    high     low   close   volume Name\n",
      "1254  2018-02-01  160.155  161.13  159.54  160.46  1692576  ACN\n",
      "1255  2018-02-02  159.980  160.27  156.63  156.90  2183611  ACN\n",
      "1256  2018-02-05  156.120  159.27  150.73  151.83  3733711  ACN\n",
      "1257  2018-02-06  150.290  155.18  149.43  154.69  4259634  ACN\n",
      "1258  2018-02-07  154.220  158.93  153.07  155.15  2918659  ACN\n",
      "The shape of the DataFrame is: (1259, 7)\n",
      "The column names are: Index(['date', 'open', 'high', 'low', 'close', 'volume', 'Name'], dtype='object')\n",
      "The data types of each column are: date       object\n",
      "open      float64\n",
      "high      float64\n",
      "low       float64\n",
      "close     float64\n",
      "volume      int64\n",
      "Name       object\n",
      "dtype: object\n",
      "The number of missing values in each column are: date      0\n",
      "open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "Name      0\n",
      "dtype: int64\n",
      "              open         high          low        close        volume\n",
      "count  1259.000000  1259.000000  1259.000000  1259.000000  1.259000e+03\n",
      "mean    101.022826   101.766440   100.348163   101.119079  2.596238e+06\n",
      "std      22.105091    22.206993    21.999712    22.129031  1.353507e+06\n",
      "min      70.580000    70.750000    69.000000    70.280000  6.018180e+05\n",
      "25%      80.680000    81.330000    80.165000    80.670000  1.879082e+06\n",
      "50%      97.800000    98.790000    96.920000    97.770000  2.328702e+06\n",
      "75%     117.020000   117.990000   116.250000   117.045000  2.972384e+06\n",
      "max     162.330000   162.600000   160.970000   162.550000  2.828439e+07\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('individual_stocks_5yr/individual_stocks_5yr/ACN_data.csv')\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Display the last 5 rows of the DataFrame\n",
    "print(df.tail())\n",
    "\n",
    "# Display the shape of the DataFrame\n",
    "print('The shape of the DataFrame is:', df.shape)\n",
    "\n",
    "# Display the column names\n",
    "print('The column names are:', df.columns)\n",
    "\n",
    "# Display the data types of each column\n",
    "print('The data types of each column are:', df.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print('The number of missing values in each column are:', df.isnull().sum())\n",
    "\n",
    "# Display summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   open    high    low  close   volume Name    t+1    t+2    t+3  \\\n",
      "0  2013-02-08  73.01  73.710  72.82  73.31  2000477  ACN    NaN    NaN    NaN   \n",
      "1  2013-02-11  73.09  73.270  72.10  73.07  1880055  ACN  73.31    NaN    NaN   \n",
      "2  2013-02-12  72.89  73.495  72.58  73.37  1710274  ACN  73.07  73.31    NaN   \n",
      "3  2013-02-13  73.32  73.710  73.20  73.56  1884631  ACN  73.37  73.07  73.31   \n",
      "4  2013-02-14  73.21  73.500  72.66  73.13  2096346  ACN  73.56  73.37  73.07   \n",
      "\n",
      "     t+4  t+5  \n",
      "0    NaN  NaN  \n",
      "1    NaN  NaN  \n",
      "2    NaN  NaN  \n",
      "3    NaN  NaN  \n",
      "4  73.31  NaN  \n"
     ]
    }
   ],
   "source": [
    "# engineer new features t+1, t+2, t+3, t+4, t+5 which are based on the future values in the target column\n",
    "# e.g. t+1 is the value of the target column 1 day in the future\n",
    "\n",
    "# Create a new column for the t+1 value\n",
    "df['t+1'] = df['close'].shift(1)\n",
    "\n",
    "# Create a new column for the t+2 value\n",
    "df['t+2'] = df['close'].shift(2)\n",
    "\n",
    "# Create a new column for the t+3 value\n",
    "df['t+3'] = df['close'].shift(3)\n",
    "\n",
    "# Create a new column for the t+4 value\n",
    "df['t+4'] = df['close'].shift(4)\n",
    "\n",
    "# Create a new column for the t+5 value\n",
    "df['t+5'] = df['close'].shift(5)\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre process\n",
    "# remove the sttock name column\n",
    "df = df.drop('Name', axis=1)\n",
    "\n",
    "#drop the date column\n",
    "df = df.drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export df to a csv file\n",
    "df.to_csv('ACN_data_timeseries_validate_preprocess.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the mean squared errors is: 0.19721058591497273\n",
      "The mean of the root mean squared errors is: 0.4370585106025078\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Standardize the features excluding 'date'\n",
    "# We are skipping the standardization of the features, as the features are already standardized (they are withing the same range, e.g. high, medium, low etc.)\n",
    "\n",
    "# drop na\n",
    "df = df.dropna()\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df.drop('close', axis=1)\n",
    "y = df['close']\n",
    "\n",
    "# Initialize the TimeSeriesSplit object, the time series split ensure that the training set is always before the test set\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize a list to store the mean squared errors\n",
    "mse = []\n",
    "\n",
    "# root mean square error\n",
    "rmse = []\n",
    "\n",
    "# Loop over the time series cross-validation splits\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the mean squared error\n",
    "    mse.append(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # Calculate the root mean squared error\n",
    "    rmse.append(np.sqrt(mean_squared_error(y_test, y_pred)))  \n",
    "\n",
    "# Print the mean of the mean squared errors\n",
    "print('The mean of the mean squared errors is:', np.mean(mse))\n",
    "\n",
    "# Print the mean of the root mean squared errors\n",
    "print('The mean of the root mean squared errors is:', np.mean(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the model to predict the values for each of the rows and export in a csv file\n",
    "# Make predictions\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Create a new column for the predictions\n",
    "df['predictions'] = y_pred\n",
    "\n",
    "# Export the DataFrame to a new CSV file\n",
    "df.to_csv('ACN_data_timeseries_validate_predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
