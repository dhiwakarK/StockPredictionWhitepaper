{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including pandas, numpy, and sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical operations\n",
    "from sklearn.model_selection import TimeSeriesSplit  # For time series cross-validation\n",
    "from sklearn.linear_model import LinearRegression  # For the linear regression model\n",
    "from sklearn.metrics import mean_squared_error  # For calculating the mean squared error\n",
    "from sklearn.preprocessing import StandardScaler  # For standardizing the features\n",
    "from matplotlib import pyplot as plt  # For data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Explore the Dataset\n",
    "Load the ACN_data.csv file into a pandas DataFrame and perform initial exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   open    high    low  close   volume Name\n",
      "0  2013-02-08  73.01  73.710  72.82  73.31  2000477  ACN\n",
      "1  2013-02-11  73.09  73.270  72.10  73.07  1880055  ACN\n",
      "2  2013-02-12  72.89  73.495  72.58  73.37  1710274  ACN\n",
      "3  2013-02-13  73.32  73.710  73.20  73.56  1884631  ACN\n",
      "4  2013-02-14  73.21  73.500  72.66  73.13  2096346  ACN\n",
      "            date     open    high     low   close   volume Name\n",
      "1254  2018-02-01  160.155  161.13  159.54  160.46  1692576  ACN\n",
      "1255  2018-02-02  159.980  160.27  156.63  156.90  2183611  ACN\n",
      "1256  2018-02-05  156.120  159.27  150.73  151.83  3733711  ACN\n",
      "1257  2018-02-06  150.290  155.18  149.43  154.69  4259634  ACN\n",
      "1258  2018-02-07  154.220  158.93  153.07  155.15  2918659  ACN\n",
      "The shape of the DataFrame is: (1259, 7)\n",
      "The column names are: Index(['date', 'open', 'high', 'low', 'close', 'volume', 'Name'], dtype='object')\n",
      "The data types of each column are: date       object\n",
      "open      float64\n",
      "high      float64\n",
      "low       float64\n",
      "close     float64\n",
      "volume      int64\n",
      "Name       object\n",
      "dtype: object\n",
      "The number of missing values in each column are: date      0\n",
      "open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "Name      0\n",
      "dtype: int64\n",
      "              open         high          low        close        volume\n",
      "count  1259.000000  1259.000000  1259.000000  1259.000000  1.259000e+03\n",
      "mean    101.022826   101.766440   100.348163   101.119079  2.596238e+06\n",
      "std      22.105091    22.206993    21.999712    22.129031  1.353507e+06\n",
      "min      70.580000    70.750000    69.000000    70.280000  6.018180e+05\n",
      "25%      80.680000    81.330000    80.165000    80.670000  1.879082e+06\n",
      "50%      97.800000    98.790000    96.920000    97.770000  2.328702e+06\n",
      "75%     117.020000   117.990000   116.250000   117.045000  2.972384e+06\n",
      "max     162.330000   162.600000   160.970000   162.550000  2.828439e+07\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('individual_stocks_5yr/individual_stocks_5yr/ACN_data.csv')\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Display the last 5 rows of the DataFrame\n",
    "print(df.tail())\n",
    "\n",
    "# Display the shape of the DataFrame\n",
    "print('The shape of the DataFrame is:', df.shape)\n",
    "\n",
    "# Display the column names\n",
    "print('The column names are:', df.columns)\n",
    "\n",
    "# Display the data types of each column\n",
    "print('The data types of each column are:', df.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print('The number of missing values in each column are:', df.isnull().sum())\n",
    "\n",
    "# Display summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the Data\n",
    "Clean and preprocess the data as necessary for the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values in each column are: date      0\n",
      "open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "Name      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print('The number of missing values in each column are:', missing_values)\n",
    "\n",
    "# If there are missing values, fill them with the mean of the respective column\n",
    "if missing_values.sum() > 0:\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# remove the sttock name column\n",
    "df = df.drop('Name', axis=1)\n",
    "\n",
    "#drop the date column\n",
    "df = df.drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk the Data into 10-Day Periods\n",
    "Divide the data into chunks of 10 days each for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    open    high    low  close   volume  target\n",
      "0  73.01  73.710  72.82  73.31  2000477   74.13\n",
      "1  73.09  73.270  72.10  73.07  1880055   74.13\n",
      "2  72.89  73.495  72.58  73.37  1710274   74.13\n",
      "3  73.32  73.710  73.20  73.56  1884631   74.13\n",
      "4  73.21  73.500  72.66  73.13  2096346   74.13\n",
      "        open     high      low   close   volume   target\n",
      "1245  161.60  162.498  160.200  161.75  2246733  160.155\n",
      "1246  161.21  161.880  160.820  161.43  1719976  160.155\n",
      "1247  161.29  162.050  160.640  160.88  1635846  160.155\n",
      "1248  161.20  161.990  160.540  160.60  1951898  160.155\n",
      "1249  161.12  161.750  160.615  160.79  1327113  160.155\n",
      "The shape of the new DataFrame is: (1250, 6)\n",
      "The column names of the new DataFrame are: ['open', 'high', 'low', 'close', 'volume', 'target']\n",
      "The data types of each column of the new DataFrame are: open      float64\n",
      "high      float64\n",
      "low       float64\n",
      "close     float64\n",
      "volume      int64\n",
      "target    float64\n",
      "dtype: object\n",
      "The number of missing values in each column of the new DataFrame are: open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "target    0\n",
      "dtype: int64\n",
      "              open         high          low        close        volume  \\\n",
      "count  1250.000000  1250.000000  1250.000000  1250.000000  1.250000e+03   \n",
      "mean    100.609874   101.345506    99.943038   100.708600  2.597625e+06   \n",
      "std      21.637471    21.722449    21.549293    21.669083  1.355859e+06   \n",
      "min      70.580000    70.750000    69.000000    70.280000  6.018180e+05   \n",
      "25%      80.640000    81.297500    80.150000    80.617500  1.880067e+06   \n",
      "50%      97.665000    98.405000    96.669500    97.575000  2.330404e+06   \n",
      "75%     116.907500   117.807500   116.022500   116.917500  2.972508e+06   \n",
      "max     161.600000   162.498000   160.820000   161.750000  2.828439e+07   \n",
      "\n",
      "           target  \n",
      "count  1250.00000  \n",
      "mean    101.14424  \n",
      "std      22.07301  \n",
      "min      71.81000  \n",
      "25%      80.78000  \n",
      "50%      96.98000  \n",
      "75%     116.48000  \n",
      "max     160.15500  \n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame to store the data in 10-day chunks\n",
    "df_chunks = pd.DataFrame()\n",
    "\n",
    "# Loop over the DataFrame in 10-day chunks\n",
    "for i in range(0, df.shape[0]-14, 10):\n",
    "    chunk = df.iloc[i:i+10]\n",
    "    chunk = chunk.assign(target=df.iloc[i+14]['open'])\n",
    "\n",
    "    # Use pd.concat to combine the chunks\n",
    "    df_chunks = pd.concat([df_chunks, chunk])\n",
    "\n",
    "# Reset the index of the new DataFrame\n",
    "df_chunks.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the first 5 rows of the new DataFrame\n",
    "print(df_chunks.head())\n",
    "\n",
    "# Display the last 5 rows of the new DataFrame\n",
    "print(df_chunks.tail())\n",
    "\n",
    "# Display the shape of the new DataFrame\n",
    "print('The shape of the new DataFrame is:', df_chunks.shape)\n",
    "\n",
    "# Display the column names of the new DataFrame\n",
    "print('The column names of the new DataFrame are:', df_chunks.columns.tolist())\n",
    "\n",
    "# Display the data types of each column of the new DataFrame\n",
    "print('The data types of each column of the new DataFrame are:', df_chunks.dtypes)\n",
    "\n",
    "# Check for missing values in the new DataFrame\n",
    "print('The number of missing values in each column of the new DataFrame are:', df_chunks.isnull().sum())\n",
    "\n",
    "# Display summary statistics of the new DataFrame\n",
    "print(df_chunks.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export df_chunks to a csv file\n",
    "df_chunks.to_csv('ACN_data_chunks_10days.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Linear Regression Model\n",
    "Train the linear regression model using the 40-day chunks of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the mean squared errors is: 15.1043302631968\n",
      "The mean of the root mean squared errors is: 3.7824755992075296\n"
     ]
    }
   ],
   "source": [
    "# Standardize the features excluding 'date'\n",
    "# features_to_scale = df.columns.difference(['date'])\n",
    "# scaler = StandardScaler()\n",
    "# df_scaled = df_chunks.copy()\n",
    "# df_scaled[features_to_scale] = scaler.fit_transform(df_chunks[features_to_scale])\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df_chunks.drop('target', axis=1)\n",
    "y = df_chunks['target']\n",
    "\n",
    "#X = df_scaled.drop('target', axis=1)\n",
    "#y = df_scaled['target']\n",
    "\n",
    "# Initialize the TimeSeriesSplit object\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize a list to store the mean squared errors\n",
    "mse = []\n",
    "\n",
    "# root mean square error\n",
    "rmse = []\n",
    "\n",
    "# Loop over the time series cross-validation splits\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the mean squared error\n",
    "    mse.append(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # Calculate the root mean squared error\n",
    "    rmse.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "\n",
    "# Print the mean of the mean squared errors\n",
    "print('The mean of the mean squared errors is:', np.mean(mse))\n",
    "\n",
    "# Print the mean of the root mean squared errors\n",
    "print('The mean of the root mean squared errors is:', np.mean(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the 14th Day\n",
    "Use the trained model to predict the 14th day based on the previous 10 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted value for the 24th day is: 159.15726369818015\n"
     ]
    }
   ],
   "source": [
    "# Predict the 14th day using the trained model\n",
    "# We will use the last 10 days in our dataset as input for our prediction\n",
    "\n",
    "# Select the last 10 days\n",
    "X_new = df_chunks.iloc[-10:].drop('target', axis=1)\n",
    "#X_new = df_scaled.iloc[-10:].drop('target', axis=1)\n",
    "\n",
    "# Use the model to make a prediction\n",
    "y_new_pred = model.predict(X_new)\n",
    "\n",
    "# Print the predicted value for the 44th day\n",
    "print('The predicted value for the 24th day is:', y_new_pred[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
